{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b11504d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee61be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94604b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.sample(50000, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6e6c468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398782</th>\n",
       "      <td>398782</td>\n",
       "      <td>496695</td>\n",
       "      <td>532029</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>115086</td>\n",
       "      <td>187729</td>\n",
       "      <td>187730</td>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327711</th>\n",
       "      <td>327711</td>\n",
       "      <td>454161</td>\n",
       "      <td>454162</td>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367788</th>\n",
       "      <td>367788</td>\n",
       "      <td>498109</td>\n",
       "      <td>491396</td>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151235</th>\n",
       "      <td>151235</td>\n",
       "      <td>237843</td>\n",
       "      <td>50930</td>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362916</th>\n",
       "      <td>362916</td>\n",
       "      <td>23049</td>\n",
       "      <td>492860</td>\n",
       "      <td>What are some private things you have caught p...</td>\n",
       "      <td>What makes people do evil?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292183</th>\n",
       "      <td>292183</td>\n",
       "      <td>87644</td>\n",
       "      <td>413734</td>\n",
       "      <td>How can I get free gift cards?</td>\n",
       "      <td>How do you return a gift card to get a refund?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360529</th>\n",
       "      <td>360529</td>\n",
       "      <td>161610</td>\n",
       "      <td>490327</td>\n",
       "      <td>Why do people feel pride?</td>\n",
       "      <td>Why do people feel patriotic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327759</th>\n",
       "      <td>327759</td>\n",
       "      <td>454216</td>\n",
       "      <td>127310</td>\n",
       "      <td>What are the Best tamil books about mahabharat...</td>\n",
       "      <td>What are the best new fiction books in Tamil? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226665</th>\n",
       "      <td>226665</td>\n",
       "      <td>134520</td>\n",
       "      <td>335326</td>\n",
       "      <td>Why is there no recycle bin in android?</td>\n",
       "      <td>Why can't I find the Recycle Bin in my computer?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "398782  398782  496695  532029   \n",
       "115086  115086  187729  187730   \n",
       "327711  327711  454161  454162   \n",
       "367788  367788  498109  491396   \n",
       "151235  151235  237843   50930   \n",
       "...        ...     ...     ...   \n",
       "362916  362916   23049  492860   \n",
       "292183  292183   87644  413734   \n",
       "360529  360529  161610  490327   \n",
       "327759  327759  454216  127310   \n",
       "226665  226665  134520  335326   \n",
       "\n",
       "                                                question1  \\\n",
       "398782  What is the best marketing automation tool for...   \n",
       "115086  I am poor but I want to invest. What should I do?   \n",
       "327711  I am from India and live abroad. I met a guy f...   \n",
       "367788  Why do so many people in the U.S. hate the sou...   \n",
       "151235                Consequences of Bhopal gas tragedy?   \n",
       "...                                                   ...   \n",
       "362916  What are some private things you have caught p...   \n",
       "292183                     How can I get free gift cards?   \n",
       "360529                          Why do people feel pride?   \n",
       "327759  What are the Best tamil books about mahabharat...   \n",
       "226665            Why is there no recycle bin in android?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "398782  What is the best marketing automation tool for...             1  \n",
       "115086  I am quite poor and I want to be very rich. Wh...             0  \n",
       "327711  T.I.E.T to Thapar University to Thapar Univers...             0  \n",
       "367788  My boyfriend doesnt feel guilty when he hurts ...             0  \n",
       "151235  What was the reason behind the Bhopal gas trag...             0  \n",
       "...                                                   ...           ...  \n",
       "362916                         What makes people do evil?             0  \n",
       "292183     How do you return a gift card to get a refund?             0  \n",
       "360529                      Why do people feel patriotic?             0  \n",
       "327759  What are the best new fiction books in Tamil? ...             0  \n",
       "226665   Why can't I find the Recycle Bin in my computer?             0  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f8d9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398782</th>\n",
       "      <td>398782</td>\n",
       "      <td>496695</td>\n",
       "      <td>532029</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>115086</td>\n",
       "      <td>187729</td>\n",
       "      <td>187730</td>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327711</th>\n",
       "      <td>327711</td>\n",
       "      <td>454161</td>\n",
       "      <td>454162</td>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367788</th>\n",
       "      <td>367788</td>\n",
       "      <td>498109</td>\n",
       "      <td>491396</td>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151235</th>\n",
       "      <td>151235</td>\n",
       "      <td>237843</td>\n",
       "      <td>50930</td>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362916</th>\n",
       "      <td>362916</td>\n",
       "      <td>23049</td>\n",
       "      <td>492860</td>\n",
       "      <td>What are some private things you have caught p...</td>\n",
       "      <td>What makes people do evil?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292183</th>\n",
       "      <td>292183</td>\n",
       "      <td>87644</td>\n",
       "      <td>413734</td>\n",
       "      <td>How can I get free gift cards?</td>\n",
       "      <td>How do you return a gift card to get a refund?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360529</th>\n",
       "      <td>360529</td>\n",
       "      <td>161610</td>\n",
       "      <td>490327</td>\n",
       "      <td>Why do people feel pride?</td>\n",
       "      <td>Why do people feel patriotic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327759</th>\n",
       "      <td>327759</td>\n",
       "      <td>454216</td>\n",
       "      <td>127310</td>\n",
       "      <td>What are the Best tamil books about mahabharat...</td>\n",
       "      <td>What are the best new fiction books in Tamil? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226665</th>\n",
       "      <td>226665</td>\n",
       "      <td>134520</td>\n",
       "      <td>335326</td>\n",
       "      <td>Why is there no recycle bin in android?</td>\n",
       "      <td>Why can't I find the Recycle Bin in my computer?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "398782  398782  496695  532029   \n",
       "115086  115086  187729  187730   \n",
       "327711  327711  454161  454162   \n",
       "367788  367788  498109  491396   \n",
       "151235  151235  237843   50930   \n",
       "...        ...     ...     ...   \n",
       "362916  362916   23049  492860   \n",
       "292183  292183   87644  413734   \n",
       "360529  360529  161610  490327   \n",
       "327759  327759  454216  127310   \n",
       "226665  226665  134520  335326   \n",
       "\n",
       "                                                question1  \\\n",
       "398782  What is the best marketing automation tool for...   \n",
       "115086  I am poor but I want to invest. What should I do?   \n",
       "327711  I am from India and live abroad. I met a guy f...   \n",
       "367788  Why do so many people in the U.S. hate the sou...   \n",
       "151235                Consequences of Bhopal gas tragedy?   \n",
       "...                                                   ...   \n",
       "362916  What are some private things you have caught p...   \n",
       "292183                     How can I get free gift cards?   \n",
       "360529                          Why do people feel pride?   \n",
       "327759  What are the Best tamil books about mahabharat...   \n",
       "226665            Why is there no recycle bin in android?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "398782  What is the best marketing automation tool for...             1  \n",
       "115086  I am quite poor and I want to be very rich. Wh...             0  \n",
       "327711  T.I.E.T to Thapar University to Thapar Univers...             0  \n",
       "367788  My boyfriend doesnt feel guilty when he hurts ...             0  \n",
       "151235  What was the reason behind the Bhopal gas trag...             0  \n",
       "...                                                   ...           ...  \n",
       "362916                         What makes people do evil?             0  \n",
       "292183     How do you return a gift card to get a refund?             0  \n",
       "360529                      Why do people feel patriotic?             0  \n",
       "327759  What are the best new fiction books in Tamil? ...             0  \n",
       "226665   Why can't I find the Recycle Bin in my computer?             0  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "567ab154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering-1\n",
    "new_df['q1_len'] = new_df['question1'].str.len()\n",
    "new_df['q2_len'] = new_df['question2'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e00d09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering-2\n",
    "new_df['q1_num_words'] = new_df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "new_df['q2_num_words'] = new_df['question2'].apply(lambda row: len(row.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19a1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad00ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767d8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering-3,4,5\n",
    "new_df['word_common'] = new_df.apply(common_words, axis=1)\n",
    "new_df['word_total'] = new_df.apply(total_words, axis=1)\n",
    "new_df['word_share'] = round(new_df['word_common']/new_df['word_total'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf674eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398782</th>\n",
       "      <td>398782</td>\n",
       "      <td>496695</td>\n",
       "      <td>532029</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>115086</td>\n",
       "      <td>187729</td>\n",
       "      <td>187730</td>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327711</th>\n",
       "      <td>327711</td>\n",
       "      <td>454161</td>\n",
       "      <td>454162</td>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>120</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367788</th>\n",
       "      <td>367788</td>\n",
       "      <td>498109</td>\n",
       "      <td>491396</td>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>146</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151235</th>\n",
       "      <td>151235</td>\n",
       "      <td>237843</td>\n",
       "      <td>50930</td>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362916</th>\n",
       "      <td>362916</td>\n",
       "      <td>23049</td>\n",
       "      <td>492860</td>\n",
       "      <td>What are some private things you have caught p...</td>\n",
       "      <td>What makes people do evil?</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292183</th>\n",
       "      <td>292183</td>\n",
       "      <td>87644</td>\n",
       "      <td>413734</td>\n",
       "      <td>How can I get free gift cards?</td>\n",
       "      <td>How do you return a gift card to get a refund?</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360529</th>\n",
       "      <td>360529</td>\n",
       "      <td>161610</td>\n",
       "      <td>490327</td>\n",
       "      <td>Why do people feel pride?</td>\n",
       "      <td>Why do people feel patriotic?</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327759</th>\n",
       "      <td>327759</td>\n",
       "      <td>454216</td>\n",
       "      <td>127310</td>\n",
       "      <td>What are the Best tamil books about mahabharat...</td>\n",
       "      <td>What are the best new fiction books in Tamil? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226665</th>\n",
       "      <td>226665</td>\n",
       "      <td>134520</td>\n",
       "      <td>335326</td>\n",
       "      <td>Why is there no recycle bin in android?</td>\n",
       "      <td>Why can't I find the Recycle Bin in my computer?</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "398782  398782  496695  532029   \n",
       "115086  115086  187729  187730   \n",
       "327711  327711  454161  454162   \n",
       "367788  367788  498109  491396   \n",
       "151235  151235  237843   50930   \n",
       "...        ...     ...     ...   \n",
       "362916  362916   23049  492860   \n",
       "292183  292183   87644  413734   \n",
       "360529  360529  161610  490327   \n",
       "327759  327759  454216  127310   \n",
       "226665  226665  134520  335326   \n",
       "\n",
       "                                                question1  \\\n",
       "398782  What is the best marketing automation tool for...   \n",
       "115086  I am poor but I want to invest. What should I do?   \n",
       "327711  I am from India and live abroad. I met a guy f...   \n",
       "367788  Why do so many people in the U.S. hate the sou...   \n",
       "151235                Consequences of Bhopal gas tragedy?   \n",
       "...                                                   ...   \n",
       "362916  What are some private things you have caught p...   \n",
       "292183                     How can I get free gift cards?   \n",
       "360529                          Why do people feel pride?   \n",
       "327759  What are the Best tamil books about mahabharat...   \n",
       "226665            Why is there no recycle bin in android?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "398782  What is the best marketing automation tool for...             1   \n",
       "115086  I am quite poor and I want to be very rich. Wh...             0   \n",
       "327711  T.I.E.T to Thapar University to Thapar Univers...             0   \n",
       "367788  My boyfriend doesnt feel guilty when he hurts ...             0   \n",
       "151235  What was the reason behind the Bhopal gas trag...             0   \n",
       "...                                                   ...           ...   \n",
       "362916                         What makes people do evil?             0   \n",
       "292183     How do you return a gift card to get a refund?             0   \n",
       "360529                      Why do people feel patriotic?             0   \n",
       "327759  What are the best new fiction books in Tamil? ...             0   \n",
       "226665   Why can't I find the Recycle Bin in my computer?             0   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  word_common  word_total  \\\n",
       "398782      76      77            12            12           11          24   \n",
       "115086      49      57            12            15            7          23   \n",
       "327711     105     120            25            17            2          34   \n",
       "367788      59     146            12            30            0          32   \n",
       "151235      35      50             5             9            3          13   \n",
       "...        ...     ...           ...           ...          ...         ...   \n",
       "362916      58      26            10             5            2          15   \n",
       "292183      30      46             7            11            3          17   \n",
       "360529      25      29             5             5            4          10   \n",
       "327759      80      50            12            10            5          22   \n",
       "226665      39      48             8            10            4          18   \n",
       "\n",
       "        word_share  \n",
       "398782        0.46  \n",
       "115086        0.30  \n",
       "327711        0.06  \n",
       "367788        0.00  \n",
       "151235        0.23  \n",
       "...            ...  \n",
       "362916        0.13  \n",
       "292183        0.18  \n",
       "360529        0.40  \n",
       "327759        0.23  \n",
       "226665        0.22  \n",
       "\n",
       "[50000 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature engineering-5\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44bd5e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize NLTK resources\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "SAFE_DIV = 0.0001\n",
    "\n",
    "def preprocess_and_stem(q):\n",
    "    q = str(q).lower().strip()\n",
    "    \n",
    "    # Replace certain special characters with their string equivalents\n",
    "    q = q.replace('%', ' percent')\n",
    "    q = q.replace('$', ' dollar ')\n",
    "    q = q.replace('â‚¹', ' rupee ')\n",
    "    q = q.replace('â‚¬', ' euro ')\n",
    "    q = q.replace('@', ' at ')\n",
    "    \n",
    "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
    "    q = q.replace('[math]', '')\n",
    "    \n",
    "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
    "    q = q.replace(',000,000,000 ', 'b ')\n",
    "    q = q.replace(',000,000 ', 'm ')\n",
    "    q = q.replace(',000 ', 'k ')\n",
    "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
    "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
    "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
    "    \n",
    "    # Decontracting words\n",
    "    contractions = { \n",
    "        \"ain't\": \"am not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\",\n",
    "        \"he's\": \"he is\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is\",\n",
    "        \"i'd\": \"i would\",\n",
    "        \"i'd've\": \"i would have\",\n",
    "        \"i'll\": \"i will\",\n",
    "        \"i'll've\": \"i will have\",\n",
    "        \"i'm\": \"i am\",\n",
    "        \"i've\": \"i have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"it'll've\": \"it will have\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\",\n",
    "        \"she'll've\": \"she will have\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so as\",\n",
    "        \"that'd\": \"that would\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"there'd\": \"there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there is\",\n",
    "        \"they'd\": \"they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they will\",\n",
    "        \"they'll've\": \"they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\",\n",
    "        \"what'll've\": \"what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who will\",\n",
    "        \"who'll've\": \"who will have\",\n",
    "        \"who's\": \"who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'll've\": \"you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    q_decontracted = []\n",
    "\n",
    "    for word in q.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "\n",
    "        q_decontracted.append(word)\n",
    "\n",
    "    q = ' '.join(q_decontracted)\n",
    "    q = q.replace(\"'ve\", \" have\")\n",
    "    q = q.replace(\"n't\", \" not\")\n",
    "    q = q.replace(\"'re\", \" are\")\n",
    "    q = q.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # Removing HTML tags\n",
    "    q = BeautifulSoup(q, \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove punctuations\n",
    "    pattern = re.compile('\\W')\n",
    "    q = re.sub(pattern, ' ', q).strip()\n",
    "    \n",
    "    # Stemming\n",
    "    q = ' '.join([stemmer.stem(word) for word in q.split()])\n",
    "    \n",
    "    return q\n",
    "\n",
    "def fetch_token_features(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    token_features = [0.0] * 8\n",
    "    \n",
    "    # Preprocess and stem questions\n",
    "    q1 = preprocess_and_stem(q1)\n",
    "    q2 = preprocess_and_stem(q2)\n",
    "    \n",
    "    # Convert the Sentence into Tokens\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    # Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    # Calculate token features\n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both questions is the same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both questions is the same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e45e56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_4176\\2085917016.py:171: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  q = BeautifulSoup(q, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "token_features = new_df.apply(fetch_token_features, axis=1)\n",
    "\n",
    "new_df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "new_df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "new_df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "new_df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "new_df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "new_df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "new_df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "new_df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3556cd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398782</th>\n",
       "      <td>398782</td>\n",
       "      <td>496695</td>\n",
       "      <td>532029</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>What is the best marketing automation tool for...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>115086</td>\n",
       "      <td>187729</td>\n",
       "      <td>187730</td>\n",
       "      <td>I am poor but I want to invest. What should I do?</td>\n",
       "      <td>I am quite poor and I want to be very rich. Wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.583328</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327711</th>\n",
       "      <td>327711</td>\n",
       "      <td>454161</td>\n",
       "      <td>454162</td>\n",
       "      <td>I am from India and live abroad. I met a guy f...</td>\n",
       "      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>120</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>0.115384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367788</th>\n",
       "      <td>367788</td>\n",
       "      <td>498109</td>\n",
       "      <td>491396</td>\n",
       "      <td>Why do so many people in the U.S. hate the sou...</td>\n",
       "      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>146</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151235</th>\n",
       "      <td>151235</td>\n",
       "      <td>237843</td>\n",
       "      <td>50930</td>\n",
       "      <td>Consequences of Bhopal gas tragedy?</td>\n",
       "      <td>What was the reason behind the Bhopal gas trag...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "398782  398782  496695  532029   \n",
       "115086  115086  187729  187730   \n",
       "327711  327711  454161  454162   \n",
       "367788  367788  498109  491396   \n",
       "151235  151235  237843   50930   \n",
       "\n",
       "                                                question1  \\\n",
       "398782  What is the best marketing automation tool for...   \n",
       "115086  I am poor but I want to invest. What should I do?   \n",
       "327711  I am from India and live abroad. I met a guy f...   \n",
       "367788  Why do so many people in the U.S. hate the sou...   \n",
       "151235                Consequences of Bhopal gas tragedy?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "398782  What is the best marketing automation tool for...             1   \n",
       "115086  I am quite poor and I want to be very rich. Wh...             0   \n",
       "327711  T.I.E.T to Thapar University to Thapar Univers...             0   \n",
       "367788  My boyfriend doesnt feel guilty when he hurts ...             0   \n",
       "151235  What was the reason behind the Bhopal gas trag...             0   \n",
       "\n",
       "        q1_len  q2_len  q1_num_words  q2_num_words  ...  word_total  \\\n",
       "398782      76      77            12            12  ...          24   \n",
       "115086      49      57            12            15  ...          23   \n",
       "327711     105     120            25            17  ...          34   \n",
       "367788      59     146            12            30  ...          32   \n",
       "151235      35      50             5             9  ...          13   \n",
       "\n",
       "        word_share   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "398782        0.46  0.999988  0.999988  0.999980  0.999980  0.999992   \n",
       "115086        0.30  0.666644  0.399992  0.714276  0.714276  0.583328   \n",
       "327711        0.06  0.000000  0.000000  0.499992  0.272725  0.149999   \n",
       "367788        0.00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "151235        0.23  0.749981  0.499992  0.000000  0.000000  0.599988   \n",
       "\n",
       "         ctc_max  last_word_eq  first_word_eq  \n",
       "398782  0.999992           1.0            1.0  \n",
       "115086  0.466664           1.0            1.0  \n",
       "327711  0.115384           0.0            0.0  \n",
       "367788  0.000000           0.0            0.0  \n",
       "151235  0.333330           1.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1cfa371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "def fetch_length_features(row):\n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    length_features = [0.0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    # Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens)) / 2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    \n",
    "    # Ensure strs is not empty before accessing its elements\n",
    "    if strs:\n",
    "        length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    else:\n",
    "        length_features[2] = 0.0\n",
    "    \n",
    "    return length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc90057",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_features = new_df.apply(fetch_length_features, axis=1)\n",
    "\n",
    "new_df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\n",
    "new_df['mean_len'] = list(map(lambda x: x[1], length_features))\n",
    "new_df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy Features\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fetch_fuzzy_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    fuzzy_features = [0.0]*4\n",
    "    \n",
    "    # fuzz_ratio\n",
    "    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n",
    "\n",
    "    # token_sort_ratio\n",
    "    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n",
    "\n",
    "    # token_set_ratio\n",
    "    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n",
    "\n",
    "    return fuzzy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_features = new_df.apply(fetch_fuzzy_features, axis=1)\n",
    "\n",
    "# Creating new feature columns for fuzzy features\n",
    "new_df['fuzz_ratio'] = list(map(lambda x: x[0], fuzzy_features))\n",
    "new_df['fuzz_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\n",
    "new_df['token_sort_ratio'] = list(map(lambda x: x[2], fuzzy_features))\n",
    "new_df['token_set_ratio'] = list(map(lambda x: x[3], fuzzy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the significance of features\n",
    "sns.pairplot(new_df[['ctc_min', 'cwc_min', 'csc_min', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d998ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(new_df[['ctc_max', 'cwc_max', 'csc_max', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dca333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(new_df[['last_word_eq', 'first_word_eq', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(new_df[['mean_len', 'abs_len_diff','longest_substr_ratio', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(new_df[['fuzz_ratio', 'fuzz_partial_ratio','token_sort_ratio','token_set_ratio', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TSNE for Dimentionality reduction for 15 Features(Generated after cleaning the data) to 3 dimensions\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = MinMaxScaler().fit_transform(new_df[['cwc_min', 'cwc_max', 'csc_min', 'csc_max' , 'ctc_min' , 'ctc_max' , 'last_word_eq', 'first_word_eq' , 'abs_len_diff' , 'mean_len' , 'token_set_ratio' , 'token_sort_ratio' ,  'fuzz_ratio' , 'fuzz_partial_ratio' , 'longest_substr_ratio']])\n",
    "y = new_df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d6fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne2d = TSNE(\n",
    "    n_components=2,\n",
    "    init='random', # pca\n",
    "    random_state=101,\n",
    "    method='barnes_hut',\n",
    "    n_iter=1000,\n",
    "    verbose=2,\n",
    "    angle=0.5\n",
    ").fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne3d = TSNE(\n",
    "    n_components=3,\n",
    "    init='random', # pca\n",
    "    random_state=101,\n",
    "    method='barnes_hut',\n",
    "    n_iter=1000,\n",
    "    verbose=2,\n",
    "    angle=0.5\n",
    ").fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "trace1 = go.Scatter3d(\n",
    "    x=tsne3d[:,0],\n",
    "    y=tsne3d[:,1],\n",
    "    z=tsne3d[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode='diameter',\n",
    "        color = y,\n",
    "        colorscale = 'Portland',\n",
    "        colorbar = dict(title = 'duplicate'),\n",
    "        line=dict(color='rgb(255, 255, 255)'),\n",
    "        opacity=0.75\n",
    "    )\n",
    ")\n",
    "\n",
    "data=[trace1]\n",
    "layout=dict(height=800, width=800, title='3d embedding with engineered features')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='3DBubble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac976de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_df = new_df[['question1','question2']]\n",
    "ques_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b36fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44becb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
    "\n",
    "cv = CountVectorizer(max_features=3000)\n",
    "q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df1 = pd.DataFrame(q1_arr, index=ques_df.index)\n",
    "temp_df2 = pd.DataFrame(q2_arr, index=ques_df.index)\n",
    "temp_df = pd.concat([temp_df1,temp_df2], axis=1)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a99624",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([final_df, temp_df], axis=1)\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82818646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c6acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for Random Forest Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf,open('model.pkl','wb'))\n",
    "pickle.dump(cv,open('cv.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf5754-de30-4bfb-875a-dae43608adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get the English stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Pickle the stopwords list\n",
    "with open('stopwords.pkl', 'wb') as f:\n",
    "    pickle.dump(stop_words, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f524773-18de-4eb7-95fb-1619fa36f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_point_creator(q1,q2):\n",
    "    \n",
    "    input_query = []\n",
    "    \n",
    "    # preprocess\n",
    "    q1 = preprocess(q1)\n",
    "    q2 = preprocess(q2)\n",
    "    \n",
    "    # fetch basic features\n",
    "    input_query.append(len(q1))\n",
    "    input_query.append(len(q2))\n",
    "    \n",
    "    input_query.append(len(q1.split(\" \")))\n",
    "    input_query.append(len(q2.split(\" \")))\n",
    "    \n",
    "    input_query.append(test_common_words(q1,q2))\n",
    "    input_query.append(test_total_words(q1,q2))\n",
    "    input_query.append(round(test_common_words(q1,q2)/test_total_words(q1,q2),2))\n",
    "    \n",
    "    # fetch token features\n",
    "    token_features = test_fetch_token_features(q1,q2)\n",
    "    input_query.extend(token_features)\n",
    "    \n",
    "    # fetch length based features\n",
    "    length_features = test_fetch_length_features(q1,q2)\n",
    "    input_query.extend(length_features)\n",
    "    \n",
    "    # fetch fuzzy features\n",
    "    fuzzy_features = test_fetch_fuzzy_features(q1,q2)\n",
    "    input_query.extend(fuzzy_features)\n",
    "    \n",
    "    # bow feature for q1\n",
    "    q1_bow = cv.transform([q1]).toarray()\n",
    "    \n",
    "    # bow feature for q2\n",
    "    q2_bow = cv.transform([q2]).toarray()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.hstack((np.array(input_query).reshape(1,22),q1_bow,q2_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd52762-9bbd-439b-b389-116878c42e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'Where is the capital of India?'\n",
    "q2 = 'What is the current capital of Pakistan?'\n",
    "q3 = 'Which city serves as the capital of India?'\n",
    "q4 = 'What is the business capital of India?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35126b4b-14a1-44e8-b3b8-7f7063f09ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(query_point_creator(q1,q4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3d945-3d71-4662-81ea-587613b4d490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
